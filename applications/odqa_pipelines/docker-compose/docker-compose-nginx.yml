version: "3"
services:
  haystack-api_1:
    build:
      context: ../../../docker
      dockerfile: Dockerfile
      args:
        - http_proxy=$HTTP_PROXY
        - https_proxy=$HTTPS_PROXY
        - no_proxy=$NO_PROXY
    image: "intel/ai-workflows:odqa-haystack-api"
    # Mount custom Pipeline YAML and custom Components.
    # volumes:
    #   - ./rest_api/pipeline:/home/user/rest_api/pipeline
    #network_mode: host
    ports:
      - 8001:8000
    restart: on-failure
    cpuset: "0-1"
    volumes:
      - $CUSTOMER_DIR:/home/user/data
    environment:
      # See rest_api/pipeline/pipelines.haystack-pipeline.yml for configurations of Search & Indexing Pipeline.
      - DOCUMENTSTORE_PARAMS_HOST=elasticsearch
      - DOCUMENTSTORE_PARAMS_PORT=9200
      #- PIPELINE_YAML_PATH=/home/user/rest_api/pipeline/pipelines.haystack-EmbeddingRetriever-pipeline.yml
      #- PIPELINE_YAML_PATH=/home/user/rest_api/pipeline/pipelines.haystack-pipeline.yml
      - PIPELINE_YAML_PATH=$PIPELINE_PATH
      - QUERY_PIPELINE_NAME=$PIPELINE_NAME
      - INDEX_NAME=$INDEX_NAME
      - CONCURRENT_REQUEST_PER_WORKER=48
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=$NO_PROXY
      #- ONEDNN_VERBOSE=1
      - KMP_BLOCKTIME=20
      - MKL_ENABLE_INSTRUCTIONS=AVX512_E1
        #- LD_PRELOAD=/usr/local/lib/libiomp5.so
        #- KMP_AFFINITY=granularity=fine,verbose,compact,1,0
      #- MKL_VERBOSE=1
      #- MKL_NUM_THREADS=48
      #- OMP_NUM_THREADS=48
      - COLBERT_OPT=$COLBERT_OPT
      - ENABLE_IPEX=$ENABLE_IPEX
      - IPEX_BF16=$IPEX_BF16
    depends_on:
      - elasticsearch
    # Starts REST API with only 2 workers so that it can be run on systems with just 4GB of memory
    # If you need to handle large loads of incoming requests and have memory to spare, consider increasing the number of workers
    command: "/bin/bash -c 'sleep 10 && gunicorn rest_api.application:app -b 0.0.0.0 -k uvicorn.workers.UvicornWorker --workers 2 --timeout 600'"
  haystack-api_2:
    build:
      context: ../../../docker
      dockerfile: Dockerfile
      args:
        - http_proxy=$HTTP_PROXY
        - https_proxy=$HTTPS_PROXY
        - no_proxy=$NO_PROXY
    image: "intel/ai-workflows:odqa-haystack-api"
    # Mount custom Pipeline YAML and custom Components.
    # volumes:
    #   - ./rest_api/pipeline:/home/user/rest_api/pipeline
    #network_mode: host
    ports:
      - 8002:8000
    restart: on-failure
    cpuset: "2-3"
    volumes:
      - $CUSTOMER_DIR:/home/user/data
    environment:
      # See rest_api/pipeline/pipelines.haystack-pipeline.yml for configurations of Search & Indexing Pipeline.
      - DOCUMENTSTORE_PARAMS_HOST=elasticsearch
      - DOCUMENTSTORE_PARAMS_PORT=9200
      #- PIPELINE_YAML_PATH=/home/user/rest_api/pipeline/pipelines.haystack-EmbeddingRetriever-pipeline.yml
      #- PIPELINE_YAML_PATH=/home/user/rest_api/pipeline/pipelines.haystack-pipeline.yml
      - PIPELINE_YAML_PATH=$PIPELINE_PATH
      - QUERY_PIPELINE_NAME=$PIPELINE_NAME
      - INDEX_NAME=$INDEX_NAME
      - CONCURRENT_REQUEST_PER_WORKER=48
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=$NO_PROXY
      #- ONEDNN_VERBOSE=1
      - KMP_BLOCKTIME=20
      - MKL_ENABLE_INSTRUCTIONS=AVX512_E1
        #- LD_PRELOAD=/usr/local/lib/libiomp5.so
        #- KMP_AFFINITY=granularity=fine,verbose,compact,1,0
      #- MKL_VERBOSE=1
      #- MKL_NUM_THREADS=48
      #- OMP_NUM_THREADS=48
      - COLBERT_OPT=$COLBERT_OPT
      - ENABLE_IPEX=$ENABLE_IPEX
      - IPEX_BF16=$IPEX_BF16
    depends_on:
      - elasticsearch
    # Starts REST API with only 2 workers so that it can be run on systems with just 4GB of memory
    # If you need to handle large loads of incoming requests and have memory to spare, consider increasing the number of workers
    command: "/bin/bash -c 'sleep 10 && gunicorn rest_api.application:app -b 0.0.0.0 -k uvicorn.workers.UvicornWorker --workers 2 --timeout 600'"  
  haystack-api_3:
    build:
      context: ../../../docker
      dockerfile: Dockerfile
      args:
        - http_proxy=$HTTP_PROXY
        - https_proxy=$HTTPS_PROXY
        - no_proxy=$NO_PROXY
    image: "intel/ai-workflows:odqa-haystack-api"
    # Mount custom Pipeline YAML and custom Components.
    # volumes:
    #   - ./rest_api/pipeline:/home/user/rest_api/pipeline
    #network_mode: host
    ports:
      - 8003:8000
    restart: on-failure
    cpuset: "4-5"
    volumes:
      - $CUSTOMER_DIR:/home/user/data
    environment:
      # See rest_api/pipeline/pipelines.haystack-pipeline.yml for configurations of Search & Indexing Pipeline.
      - DOCUMENTSTORE_PARAMS_HOST=elasticsearch
      - DOCUMENTSTORE_PARAMS_PORT=9200
      #- PIPELINE_YAML_PATH=/home/user/rest_api/pipeline/pipelines.haystack-EmbeddingRetriever-pipeline.yml
      #- PIPELINE_YAML_PATH=/home/user/rest_api/pipeline/pipelines.haystack-pipeline.yml
      - PIPELINE_YAML_PATH=$PIPELINE_PATH
      - QUERY_PIPELINE_NAME=$PIPELINE_NAME
      - INDEX_NAME=$INDEX_NAME
      - CONCURRENT_REQUEST_PER_WORKER=48
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=$NO_PROXY
      #- ONEDNN_VERBOSE=1
      - KMP_BLOCKTIME=20
      - MKL_ENABLE_INSTRUCTIONS=AVX512_E1
        #- LD_PRELOAD=/usr/local/lib/libiomp5.so
        #- KMP_AFFINITY=granularity=fine,verbose,compact,1,0
      #- MKL_VERBOSE=1
      #- MKL_NUM_THREADS=48
      #- OMP_NUM_THREADS=48
      - COLBERT_OPT=$COLBERT_OPT
      - ENABLE_IPEX=$ENABLE_IPEX
      - IPEX_BF16=$IPEX_BF16
    depends_on:
      - elasticsearch
    # Starts REST API with only 2 workers so that it can be run on systems with just 4GB of memory
    # If you need to handle large loads of incoming requests and have memory to spare, consider increasing the number of workers
    command: "/bin/bash -c 'sleep 10 && gunicorn rest_api.application:app -b 0.0.0.0 -k uvicorn.workers.UvicornWorker --workers 2 --timeout 600'"  
  nginx-dispatch:
    build:
      context: ../../../nginx
      args:
        - http_proxy=$HTTP_PROXY
        - https_proxy=$HTTPS_PROXY
        - no_proxy=$NO_PROXY
    image: "deepset/nginx-router:latest"
    ports:
        - 8000:80
    depends_on:
      - haystack-api_1
      - haystack-api_2
      - haystack-api_3
  elasticsearch:
    # This will start an empty elasticsearch instance (so you have to add your documents yourself)
    #image: "elasticsearch:7.9.2"
    #image: "elasticsearch:8.1.2"
    #image: "stackoverflow-es:latest"
    # If you want a demo image instead that is "ready-to-query" with some indexed articles
    # about countries and capital cities from Wikipedia:
    #image: "dingke1980/elasticsearch-stack-overflow:1.0"
    #image: "deepset/elasticsearch-countries-and-capitals"
    image: $ELASTICSEARCH_IMG
    ports:
      - 9200:9200
    restart: on-failure
    volumes:
      - $DATA_DIR:/usr/share/elasticsearch/data
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xmx4g -Xms4g

  ui:
    build:
      context: ../../../ui
      dockerfile: Dockerfile
      args:
        - http_proxy=$HTTP_PROXY
        - https_proxy=$HTTPS_PROXY
        - no_proxy=$NO_PROXY
    image: "intel/ai-workflows:odqa-haystack-ui"
    #network_mode: host
    ports:
      - 8501:8501
    restart: on-failure
    volumes:
      - $UI_CONFIG_DIR:/home/user/data/
    environment:
      - API_ENDPOINT=http://nginx-dispatch:8000
      #- API_ENDPOINT=http://localhost:8000
      - EVAL_FILE=ui/eval_labels_example.csv
      - PIPELINE_PATH=$PIPELINE_PATH
      # The value fot the following variables will be read from the host, if present.
      # They can also be temporarily set for docker-compose, for example:
      # DISABLE_FILE_UPLOAD=1 DEFAULT_DOCS_FROM_RETRIEVER=5 docker-compose up
      - DISABLE_FILE_UPLOAD=True
      - DEFAULT_QUESTION_AT_STARTUP
      - DEFAULT_DOCS_FROM_RETRIEVER
      - DEFAULT_NUMBER_OF_ANSWERS
    command: "/bin/bash -c 'sleep 15 && python -m streamlit run ui/webapp.py'"

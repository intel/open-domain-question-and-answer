version: "3"
services:

  haystack-api:
    build:
      context: ../../../docker
      dockerfile: Dockerfile-GPU
      args:
        - http_proxy=$HTTP_PROXY
        - https_proxy=$HTTPS_PROXY
        - no_proxy=$NO_PROXY
    image: "intel/ai-workflows:odqa-haystack-api-gpu"
    # in recent docker-compose version you can enable GPU resources. Make sure to fulfill the prerequisites listed here: https://docs.docker.com/compose/gpu-support/
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            #count: 1
            capabilities: [gpu]
    # # Mount custom Pipeline YAML and custom Components.
    # volumes:
    #   - ./rest_api/pipeline:/home/user/rest_api/pipeline
    ports:
      - 8000:8000
    restart: on-failure

    volumes:
      - $CUSTOMER_DIR:/home/user/data

    environment:
      # See rest_api/pipeline/pipelines.haystack-pipeline.yml for configurations of Search & Indexing Pipeline.
      #- DOCUMENTSTORE_PARAMS_HOST=elasticsearch
        #- PIPELINE_YAML_PATH=/home/user/rest_api/pipeline/pipelines_dpr.haystack-pipeline.yml
      - PIPELINE_YAML_PATH=$PIPELINE_PATH
      - QUERY_PIPELINE_NAME=$PIPELINE_NAME
      #- INDEX_NAME=$INDEX_NAME
      - CONCURRENT_REQUEST_PER_WORKER
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=$NO_PROXY
      #- COLBERT_OPT=$COLBERT_OPT
    depends_on:
      - postsql-db
    command: "/bin/bash -c 'sleep 10 && gunicorn rest_api.application:app -b 0.0.0.0 -k uvicorn.workers.UvicornWorker --workers 1 --timeout 600 --graceful-timeout 600'"

  postsql-db:
    image: "postgres:14.1-alpine"
    ports:
      - 5432:5432
    restart: on-failure
    environment:
      - POSTGRES_HOST_AUTH_METHOD=$POSTGRES_HOST_AUTH_METHOD
    volumes:
      - $DATA_DIR:/var/lib/postgresql/data
    # environment:
    #   - discovery.type=single-node

  ui:
    build:
      context: ../../../ui
      dockerfile: Dockerfile
      args:
        - http_proxy=$HTTP_PROXY
        - https_proxy=$HTTPS_PROXY
    image: "intel/ai-workflows:odqa-haystack-ui"
    ports:
      - 8501:8501
    restart: on-failure
    volumes:
      - $UI_CONFIG_DIR:/home/user/data/
    environment:
      - API_ENDPOINT=http://haystack-api:8000
      - EVAL_FILE=ui/eval_labels_example.csv
      - PIPELINE_PATH=$PIPELINE_PATH
      # The value fot the following variables will be read from the host, if present.
      # They can also be temporarily set for docker-compose, for example:
      # DISABLE_FILE_UPLOAD=1 DEFAULT_DOCS_FROM_RETRIEVER=5 docker-compose up
      - DISABLE_FILE_UPLOAD=True
      - DEFAULT_QUESTION_AT_STARTUP
      - DEFAULT_DOCS_FROM_RETRIEVER
      - DEFAULT_NUMBER_OF_ANSWERS
    command: "/bin/bash -c 'sleep 15 && python -m streamlit run ui/webapp.py'"

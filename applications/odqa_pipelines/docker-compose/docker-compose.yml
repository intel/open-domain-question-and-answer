version: "3"
services:
  haystack-api:
    build:
      context: ../../../docker
      dockerfile: Dockerfile
      args:
        - http_proxy=$HTTP_PROXY
        - https_proxy=$HTTPS_PROXY
        - no_proxy=$NO_PROXY
    image: "intel/ai-workflows:odqa-haystack-api"
    ports:
      - 8000:8000
    restart: on-failure
    #cpuset: "0"
    # Mount custom Pipeline YAML and custom Components.
    #volumes:
    #  - $CUSTOMER_DIR:/home/user/data
    environment:
      - DOCUMENTSTORE_PARAMS_HOST=elasticsearch
      - DOCUMENTSTORE_PARAMS_PORT=9200
      # See rest_api/pipeline/pipelines.haystack-pipeline.yml for configurations of Search & Indexing Pipeline.
      - PIPELINE_YAML_PATH=$PIPELINE_PATH
      - QUERY_PIPELINE_NAME=$PIPELINE_NAME
      - CONCURRENT_REQUEST_PER_WORKER=48
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=$NO_PROXY
      - KMP_BLOCKTIME=20
      - MKL_ENABLE_INSTRUCTIONS=AVX512_E1
      - COLBERT_OPT=$COLBERT_OPT
      - ENABLE_IPEX=$ENABLE_IPEX
      - IPEX_BF16=$IPEX_BF16
      - CHECKPOINT_PATH=$CHECKPOINT_PATH
      - IS_DICT_CHECKPOINT=$IS_DICT_CHECKPOINT
    depends_on:
      - elasticsearch
    # Starts REST API with only 2 workers so that it can be run on systems with just 4GB of memory
    # If you need to handle large loads of incoming requests and have memory to spare, consider increasing the number of workers
    command: "/bin/bash -c 'sleep 10 && gunicorn rest_api.application:app -b 0.0.0.0 -k uvicorn.workers.UvicornWorker --workers 1 --timeout 600'"
  elasticsearch:
    # This will start an empty elasticsearch instance (so you have to add your documents yourself)
    # If you want a demo image instead that is "ready-to-query" with some indexed articles
    # about countries and capital cities from Wikipedia:
    #image: "deepset/elasticsearch-countries-and-capitals"
    image: $ELASTICSEARCH_IMG
    ports:
      - 9200:9200
    restart: on-failure
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xmx4g -Xms4g
    volumes:
      - $DATA_DIR:/usr/share/elasticsearch/data
  ui:
    build:
      context: ../../../ui
      dockerfile: Dockerfile
      args:
        - http_proxy=$HTTP_PROXY
        - https_proxy=$HTTPS_PROXY
        - no_proxy=$NO_PROXY
    image: "intel/ai-workflows:odqa-haystack-ui"
    #network_mode: host
    ports:
      - 8501:8501
    restart: on-failure
    volumes:
      - $UI_CONFIG_DIR:/home/user/data/
    environment:
      - PIPELINE_PATH=$PIPELINE_PATH
      - API_ENDPOINT=http://haystack-api:8000
      #- API_ENDPOINT=http://localhost:8000
      # The value fot the following variables will be read from the host, if present.
      # They can also be temporarily set for docker-compose, for example:
      # DISABLE_FILE_UPLOAD=1 DEFAULT_DOCS_FROM_RETRIEVER=5 docker-compose up
      - DISABLE_FILE_UPLOAD=True
      - DEFAULT_QUESTION_AT_STARTUP
      - DEFAULT_DOCS_FROM_RETRIEVER
      - DEFAULT_NUMBER_OF_ANSWERS
    command: "/bin/bash -c 'sleep 15 && python -m streamlit run ui/webapp.py'"
